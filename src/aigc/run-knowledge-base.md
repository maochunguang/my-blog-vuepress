---
title: æœ¬åœ°æ­å»ºchatgptçŸ¥è¯†åº“
icon: fab fa-markdown
order: 2
category:
  - AIGC
tag:
  - langchain
  - chatgpt
---
ğŸ¤–ï¸ ä¸€ç§åˆ©ç”¨ langchain æ€æƒ³å®ç°çš„åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„é—®ç­”åº”ç”¨ï¼Œç›®æ ‡æœŸæœ›å»ºç«‹ä¸€å¥—å¯¹ä¸­æ–‡åœºæ™¯ä¸å¼€æºæ¨¡å‹æ”¯æŒå‹å¥½ã€å¯ç¦»çº¿è¿è¡Œçš„çŸ¥è¯†åº“é—®ç­”è§£å†³æ–¹æ¡ˆã€‚
<!-- more -->

## langchain-chatchatæ­å»ºçŸ¥è¯†åº“åŸç†
ğŸ¤–ï¸ ä¸€ç§åˆ©ç”¨ langchain æ€æƒ³å®ç°çš„åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„é—®ç­”åº”ç”¨ï¼Œç›®æ ‡æœŸæœ›å»ºç«‹ä¸€å¥—å¯¹ä¸­æ–‡åœºæ™¯ä¸å¼€æºæ¨¡å‹æ”¯æŒå‹å¥½ã€å¯ç¦»çº¿è¿è¡Œçš„çŸ¥è¯†åº“é—®ç­”è§£å†³æ–¹æ¡ˆã€‚

å®ç°åŸç†å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿‡ç¨‹åŒ…æ‹¬åŠ è½½æ–‡ä»¶ -> è¯»å–æ–‡æœ¬ -> æ–‡æœ¬åˆ†å‰² -> æ–‡æœ¬å‘é‡åŒ– -> é—®å¥å‘é‡åŒ– -> åœ¨æ–‡æœ¬å‘é‡ä¸­åŒ¹é…å‡ºä¸é—®å¥å‘é‡æœ€ç›¸ä¼¼çš„ top kä¸ª -> åŒ¹é…å‡ºçš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æ·»åŠ åˆ° promptä¸­ -> æäº¤ç»™ LLMç”Ÿæˆå›ç­”ã€‚

![åŸç†å›¾](https://blog-pics-1252092369.cos.ap-beijing.myqcloud.com/langchain-chatglm.png)

## ç¯å¢ƒå‡†å¤‡
### ç¡¬ä»¶å‡†å¤‡ï¼š
win11+wsl2ï¼Œæ˜¾å¡æœ€å¥½æ˜¯Nå¡ï¼Œæˆ‘çš„æ˜¯2080ti22gï¼ˆé­”æ”¹ç‰ˆï¼‰ï¼Œè¿™æ¬¾æ€§ä»·æ¯”å¾ˆé«˜ï¼Œæ¨èè´­ä¹°ã€‚

### è½¯ä»¶å‡†å¤‡ï¼š
1. å®‰è£…pythonç¯å¢ƒç®¡ç†å·¥å…·ï¼Œ`pyenv`æˆ–è€…`conda`ï¼Œæˆ‘è¿™é‡Œç”¨çš„`pyenv`ã€‚
2. å®‰è£…å¥½python 3.10ç‰ˆæœ¬ï¼Œ
3. å®‰è£…å¥½æ˜¾å¡é©±åŠ¨å’Œcudaï¼Œæ ¹æ®æ˜¾å¡æ¥å®‰è£…ç‰ˆæœ¬ï¼Œåœ¨win11ä¸‹å®‰è£…å°±è¡Œã€‚
4. å®‰è£…å¥½git
5. æœ‰æ¢¯å­çš„è¯å»ºè®®æ•´ä¸€ä¸ªã€‚

#### éªŒè¯æ˜¾å¡ï¼Œpythonå’Œcuda
æ–¹æ³•ä¸€ã€
æ‰“å¼€å‘½ä»¤æç¤ºç¬¦æˆ– PowerShellã€‚è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š`nvidia-smi`åœ¨è¾“å‡ºä¸­ï¼Œå¯ä»¥çœ‹åˆ°æ˜¾å¡çš„åç§°å’Œæ”¯æŒçš„ CUDA ç‰ˆæœ¬ã€‚

æ–¹æ³•äºŒã€
ä½¿ç”¨ Pythonå¯¼å…¥ torch åº“ã€‚
ä½¿ç”¨`torch.cuda.is_available()` å‡½æ•°æ¥æ£€æŸ¥æ˜¯å¦æ”¯æŒ CUDAã€‚
ä½¿ç”¨`torch.cuda.get_device_name(0)` å‡½æ•°æ¥è·å–ç¬¬ä¸€ä¸ªæ˜¾å¡çš„åç§°ã€‚
ä½¿ç”¨`torch.cuda.get_device_properties(0)`å‡½æ•°æ¥è·å–ç¬¬ä¸€ä¸ªæ˜¾å¡çš„å±æ€§ï¼Œå…¶ä¸­åŒ…æ‹¬æ”¯æŒçš„ CUDA ç‰ˆæœ¬ã€‚
ç¤ºä¾‹ä»£ç ï¼š
```python
import torch

if torch.cuda.is_available():
    print(f"æ”¯æŒ CUDAï¼Œç¬¬ä¸€ä¸ªæ˜¾å¡åç§°ï¼š{torch.cuda.get_device_name(0)}")
    print(f"ç¬¬ä¸€ä¸ªæ˜¾å¡æ”¯æŒçš„ CUDA ç‰ˆæœ¬ï¼š{torch.cuda.get_device_properties(0).cuda_version}")
else:
    print("ä¸æ”¯æŒ CUDA")
```
è¿™é‡Œå¯èƒ½æœ‰ä¸ªå°å‘ï¼Œå¦‚æœwin11é‡Œå¯ä»¥çœ‹åˆ°gpuå¯ç”¨ï¼Œä½†æ˜¯wsl2ä¸­æ— å¯ç”¨cpuï¼Œå¯ä»¥æŠŠwsl2å…ˆåœæ‰ï¼Œå†é‡æ–°å¯åŠ¨ã€‚

## æœ¬åœ°æ­å»ºæ­¥éª¤
### 1ã€å¤åˆ¶é¡¹ç›®
```bash
git clone https://github.com/chatchat-space/Langchain-Chatchat.git; 
cd Langchain-Chatchat
```
### 2ã€åˆ›å»ºç¯å¢ƒ
è¿™é‡Œä¸ç®¡ä½ ç”¨ä»€ä¹ˆè™šæ‹Ÿç¯å¢ƒç®¡ç†éƒ½å¯ä»¥ï¼Œä¸€å®šç”¨ä¸€ä¸ªå•ç‹¬çš„ç¯å¢ƒï¼Œé˜²æ­¢ä¾èµ–å†²çªå’ŒæŠ¥é”™ã€‚è¿™é‡Œæ˜¯ä»¥`pyenv`ä¸ºä¾‹å­ã€‚
```bash
python -m venv test_langchain_chat
source test_langchain_chat/bin/activate
```

### 3ã€å®‰è£…ä¾èµ–
è¿™é‡Œå®‰è£…çš„é€‚åˆå¦‚æœä¸‹è½½çš„å¤ªæ…¢ï¼Œå¯ä»¥ä½¿ç”¨å®‰è£…æºï¼Œ
#### aã€ ä½¿ç”¨-iå‚æ•°å®‰è£…
`pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ package_name`ã€‚

#### bã€å…¨å±€è®¾ç½®å®‰è£…æº
å¯ä»¥ä¿®æ”¹ pip çš„é…ç½®æ–‡ä»¶ pip.conf æ¥å…¨å±€æŒ‡å®š pip é•œåƒæºã€‚pip.conf æ–‡ä»¶ä½äºç”¨æˆ·ç›®å½•ä¸‹çš„ .config/pip ç›®å½•ä¸­ã€‚
åœ¨ pip.conf æ–‡ä»¶ä¸­ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š
```
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple/
```
ä¿å­˜å¹¶å…³é—­ pip.conf æ–‡ä»¶åï¼Œé‡å¯ pipã€‚

#### cã€å®‰è£…æ‰€æœ‰ä¾èµ–
```bash
# å®‰è£…å…¨éƒ¨ä¾èµ–
pip install -r requirements.txt 
pip install -r requirements_api.txt
pip install -r requirements_webui.txt 
```

### 4ã€ä¸‹è½½æ¨¡å‹
åœ¨æœ¬åœ°æˆ–ç¦»çº¿ç¯å¢ƒä¸‹è¿è¡Œï¼Œéœ€è¦é¦–å…ˆå°†é¡¹ç›®æ‰€éœ€çš„æ¨¡å‹ä¸‹è½½è‡³æœ¬åœ°ï¼Œé€šå¸¸å¼€æº LLM ä¸ Embedding æ¨¡å‹å¯ä»¥ä» HuggingFaceä¸‹è½½ã€‚ä»¥æœ¬é¡¹ç›®ä¸­é»˜è®¤ä½¿ç”¨çš„ LLM æ¨¡å‹ THUDM/ChatGLM3-6B ä¸ Embedding æ¨¡å‹ BAAI/bge-large-zh ä¸ºä¾‹ï¼š

ä¸‹è½½æ¨¡å‹å¸¸ç”¨çš„ç½‘ç«™æœ‰ä»¥ä¸‹å‡ ä¸ªï¼Œ
1. https://huggingface.co/
2. https://www.modelscope.cn/models

ä¸‹è½½æ–¹å¼æœ‰ä»¥ä¸‹å‡ ç§
#### aã€git lfsä¸‹è½½
å…ˆå®‰è£…git lfsï¼Œå¦‚ä¸‹ï¼š
https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage
```bash
git lfs install
git clone https://huggingface.co/THUDM/chatglm3-6b
git clone https://huggingface.co/BAAI/bge-large-zh
```

#### bã€ä½¿ç”¨huggingface_hubä¸‹è½½
è¯¦ç»†çš„æ•™ç¨‹å¯ä»¥å‚è€ƒï¼šhttps://hf-mirror.com/docs/huggingface_hub/guides/download
```bash
pip install --upgrade huggingface_hub
from huggingface_hub import hf_hub_download
hf_hub_download(repo_id="lysandre/arxiv-nlp", filename="config.json")
```
#### cã€ä½¿ç”¨modelscope-cliä¸‹è½½
```bash
## å®‰è£…ä¸‹è½½å®¢æˆ·ç«¯
pip install modelscope-cli

## ä¸‹è½½æ¨¡å‹
modelscope download bert-base-chinese
 
```

### 5ã€ä¿®æ”¹å’Œåˆå§‹åŒ–é…ç½®
#### aã€åˆå§‹åŒ–é…ç½®
```bash
## å¤åˆ¶é…ç½®æ–‡ä»¶
python copy_config_example.py
## åˆå§‹åŒ–çŸ¥è¯†åº“
python init_database.py --recreate-vs
```

#### bã€ä¿®æ”¹æ¨¡å‹é…ç½®
ä¿®æ”¹`configs/model_config.py`
å»ºè®®æŠŠæ‰€æœ‰çš„æ¨¡å‹æ”¾åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œåç»­å¦‚æœç©å…¶ä»–å¤§æ¨¡å‹æŒ‡å®šä»¥ä¸‹ç›®å½•å°±è¡Œäº†ã€‚

```python
MODEL_ROOT_PATH = "/home/xx/soft/ai-models"
```

### 6ã€å¯åŠ¨è°ƒè¯•
æ‰§è¡Œå‘½ä»¤å¯åŠ¨æœåŠ¡ï¼›è®¿é—®http://localhost:8501/
```bash
python startup.py -a
```
### 7ã€çŸ¥è¯†åº“æµ‹è¯•
æˆ‘è¿™é‡Œä¸Šä¼ äº†åŸºæœ¬epubä¹¦ç±ï¼Œéƒ½æ˜¯é‡‘èç›¸å…³çš„ã€‚æœç´¢ä»€ä¹ˆæ˜¯æŒ‡æ•°åŸºé‡‘æ˜¯å¯ä»¥æ˜¾ç¤ºçŸ¥è¯†åº“æ¥æºçš„

![img](https://blog-pics-1252092369.cos.ap-beijing.myqcloud.com/v2-cfc6b68f151b1ea8148093e0034ad686_1440w.webp)

![img](https://blog-pics-1252092369.cos.ap-beijing.myqcloud.com/v2-d3494e31e9a8c04fcd98da270adef82d_1440w.webp)